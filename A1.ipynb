{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "  def __init__(self, learning_rate):\n",
    "    self.index_dict = {} #dictionary of words:index in bag of words vector\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    ...\n",
    "\n",
    "  def predict(self, X):\n",
    "    ...\n",
    "\n",
    "  def transform(self, X):\n",
    "    ...\n",
    "\n",
    "  def score(self, X, y):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Part1\n",
    "**Implementation task:** Implement a parser for the dataset. The output should be a list/array of strings (`X_raw`) and a list/array of labels (`y`) encoded as {-1,1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tar():\n",
    "    # open file \n",
    "    review_file = tarfile.open('review_polarity.tar.gz') \n",
    "  \n",
    "    # extracting file \n",
    "    review_file.extractall('.') \n",
    "  \n",
    "    review_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir_list, dir_path, review_polarity):\n",
    "    words = set()\n",
    "    reviews = []\n",
    "    sentiment = []\n",
    "    \n",
    "    for file_name in dir_list:\n",
    "        if isinstance(file_name, str):\n",
    "            f = open(os.path.join(dir_path, file_name),'r')\n",
    "            review = f.read()\n",
    "            reviews.append(review)\n",
    "            words = words|set(review.split()) #.strip(\"\") for future comparison\n",
    "            sentiment.append(review_polarity)\n",
    "            f.close()\n",
    "    return np.array(reviews), np.array(sentiment), words\n",
    "        \n",
    "#get reviews. add to init when done.\n",
    "read_tar()\n",
    "neg_path = 'txt_sentoken/neg'\n",
    "pos_path = 'txt_sentoken/pos'\n",
    "neg_files = os.listdir(neg_path)\n",
    "pos_files = os.listdir(pos_path)\n",
    "\n",
    "neg_rev, neg_sent, neg_words = get_data(neg_files, neg_path, -1)\n",
    "pos_rev, pos_sent, pos_words = get_data(pos_files, pos_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#form word bag, X_raw, and prediction sets\n",
    "words = neg_words|pos_words\n",
    "X_raw = np.concatenate((neg_rev,pos_rev),axis=0)\n",
    "y = np.concatenate((neg_sent,pos_sent),axis=0)\n",
    "words = sorted(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffles both predictions and raw data with same permutation.\n",
    "def shuffle(data, labels):\n",
    "    p = np.random.permutation(len(data))\n",
    "    return data[p], labels[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw, y = shuffle(X_raw, y)\n",
    "X_raw[1:5]\n",
    "y[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimensions look good! now to move onto implementing BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Part2\n",
    "**Implementation task:** You should re-implement the feature extraction above. The list/array called `ordered_vocabulary` should contain the words for each feature dimension, and X should contain the BOW binary vectors. Remember to use the same method names as the original sklearn class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(self, data):\n",
    "    sparse_data = []\n",
    "    for review in data:\n",
    "        review_list = review.split()\n",
    "        sparse_review = np.zeros(len(review_list))\n",
    "        for word in review_list:\n",
    "            sparse_review[self.index_dict[word]] = 1\n",
    "    sparse_data.append(sparse_review)        \n",
    "    assert len(data) == len(sparse_data)\n",
    "    return np.array(sparse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X = vectorizer.transform(X_raw)\n",
    "X = X.todense()                   # sklearn will output a sparse matrix\n",
    "X[X>1] = 1                        # Turns the count vectors into binary vectors\n",
    "X = np.asarray(X)                 # Turns the matrix into an array. SGD model doesn't support matrix in the newer sklearn module version \n",
    "\n",
    "ordered_vocabulary = vectorizer.get_feature_names_out()\n",
    "vocabulary = set(ordered_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Part3\n",
    "**Implementation task:** You should implement your versions of the following parts (you can also find this in the slides):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Part4\n",
    "**Implementation task:** Implement code for printing a sorted table of your sampled hyperparameters. Note, you do not have to reimplement the grid search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
